# This file was created by the command:
# steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3_cleaned/tdnn_sp/configs/network.xconfig --config-dir exp/nnet3_cleaned/tdnn_sp/configs
# It contains the entire neural network, but with those
# components that would normally require fixed vectors/matrices
# read from disk, replaced with random initialization
# (this applies to the LDA-like transform and the
# presoftmax-prior-scale, if applicable).  This file
# is used only to work out the left-context and right-context
# of the network.

input-node name=ivector dim=100
input-node name=input dim=40
component name=lda type=FixedAffineComponent input-dim=300 output-dim=300
component-node name=lda component=lda input=Append(Offset(input, -2), Offset(input, -1), input, Offset(input, 1), Offset(input, 2), ReplaceIndex(ivector, t, 0))
component name=tdnn0.affine type=NaturalGradientAffineComponent input-dim=300 output-dim=1280  max-change=0.75
component-node name=tdnn0.affine component=tdnn0.affine input=lda
component name=tdnn0.relu type=RectifiedLinearComponent dim=1280 self-repair-scale=1e-05
component-node name=tdnn0.relu component=tdnn0.relu input=tdnn0.affine
component name=tdnn0.batchnorm type=BatchNormComponent dim=1280 target-rms=1.0
component-node name=tdnn0.batchnorm component=tdnn0.batchnorm input=tdnn0.relu
component name=tdnn1.affine type=NaturalGradientAffineComponent input-dim=2560 output-dim=1280  max-change=0.75
component-node name=tdnn1.affine component=tdnn1.affine input=Append(Offset(tdnn0.batchnorm, -1), Offset(tdnn0.batchnorm, 2))
component name=tdnn1.relu type=RectifiedLinearComponent dim=1280 self-repair-scale=1e-05
component-node name=tdnn1.relu component=tdnn1.relu input=tdnn1.affine
component name=tdnn1.batchnorm type=BatchNormComponent dim=1280 target-rms=1.0
component-node name=tdnn1.batchnorm component=tdnn1.batchnorm input=tdnn1.relu
component name=tdnn2.affine type=NaturalGradientAffineComponent input-dim=2560 output-dim=1280  max-change=0.75
component-node name=tdnn2.affine component=tdnn2.affine input=Append(Offset(tdnn1.batchnorm, -3), Offset(tdnn1.batchnorm, 3))
component name=tdnn2.relu type=RectifiedLinearComponent dim=1280 self-repair-scale=1e-05
component-node name=tdnn2.relu component=tdnn2.relu input=tdnn2.affine
component name=tdnn2.batchnorm type=BatchNormComponent dim=1280 target-rms=1.0
component-node name=tdnn2.batchnorm component=tdnn2.batchnorm input=tdnn2.relu
component name=tdnn3.affine type=NaturalGradientAffineComponent input-dim=2560 output-dim=1280  max-change=0.75
component-node name=tdnn3.affine component=tdnn3.affine input=Append(Offset(tdnn2.batchnorm, -7), Offset(tdnn2.batchnorm, 2))
component name=tdnn3.relu type=RectifiedLinearComponent dim=1280 self-repair-scale=1e-05
component-node name=tdnn3.relu component=tdnn3.relu input=tdnn3.affine
component name=tdnn3.batchnorm type=BatchNormComponent dim=1280 target-rms=1.0
component-node name=tdnn3.batchnorm component=tdnn3.batchnorm input=tdnn3.relu
component name=tdnn4.affine type=NaturalGradientAffineComponent input-dim=1280 output-dim=1280  max-change=0.75
component-node name=tdnn4.affine component=tdnn4.affine input=tdnn3.batchnorm
component name=tdnn4.relu type=RectifiedLinearComponent dim=1280 self-repair-scale=1e-05
component-node name=tdnn4.relu component=tdnn4.relu input=tdnn4.affine
component name=tdnn4.batchnorm type=BatchNormComponent dim=1280 target-rms=1.0
component-node name=tdnn4.batchnorm component=tdnn4.batchnorm input=tdnn4.relu
component name=output.affine type=NaturalGradientAffineComponent input-dim=1280 output-dim=5688  max-change=1.5 param-stddev=0.0 bias-stddev=0.0
component-node name=output.affine component=output.affine input=tdnn4.batchnorm
component name=output.log-softmax type=LogSoftmaxComponent dim=5688
component-node name=output.log-softmax component=output.log-softmax input=output.affine
output-node name=output input=output.log-softmax objective=linear
