local/nnet3/run_tdnn.sh: creating neural net configs
steps/nnet3/get_egs.sh --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3_cleaned/ivectors_train_960_cleaned_sp_hires --left-context 13 --right-context 9 --left-context-initial -1 --right-context-final -1 --stage 0 --samples-per-iter 400000 --frames-per-eg 8 --srand 0 data/train_960_cleaned_sp_hires exp/tri6b_cleaned_ali_train_960_cleaned_sp exp/nnet3_cleaned/tdnn_sp/egs
File data/train_960_cleaned_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/nnet3_cleaned/tdnn_sp/egs/.nodelete
steps/nnet3/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
steps/nnet3/get_egs.sh: creating 323 archives, each with 399543 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (13,9)
steps/nnet3/get_egs.sh: copying data alignments
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments
steps/nnet3/get_egs.sh: Finished preparing training examples
exp/nnet3_cleaned/tdnn_sp: num-iters=7752 nj=3..1 num-params=19.1M dim=40+100->5688 combine=-0.90->-0.90 (over 22) loglike:train/valid[5162,7751,combined]=(-0.88,-0.87,-0.86/-0.99,-0.97,-0.97) accuracy:train/valid[5162,7751,combined]=(0.733,0.738,0.740/0.707,0.709,0.712)
steps/nnet3/decode.sh --nj 10 --cmd run.pl --mem 4G --online-ivector-dir exp/nnet3_cleaned/ivectors_test_other_hires exp/tri6b_cleaned/graph_tgsmall data/test_other_hires exp/nnet3_cleaned/tdnn_sp/decode_test_other_tgsmall
steps/nnet3/decode.sh --nj 10 --cmd run.pl --mem 4G --online-ivector-dir exp/nnet3_cleaned/ivectors_test_clean_hires exp/tri6b_cleaned/graph_tgsmall data/test_clean_hires exp/nnet3_cleaned/tdnn_sp/decode_test_clean_tgsmall
steps/nnet3/decode.sh --nj 10 --cmd run.pl --mem 4G --online-ivector-dir exp/nnet3_cleaned/ivectors_dev_other_hires exp/tri6b_cleaned/graph_tgsmall data/dev_other_hires exp/nnet3_cleaned/tdnn_sp/decode_dev_other_tgsmall
steps/nnet3/decode.sh --nj 10 --cmd run.pl --mem 4G --online-ivector-dir exp/nnet3_cleaned/ivectors_dev_clean_hires exp/tri6b_cleaned/graph_tgsmall data/dev_clean_hires exp/nnet3_cleaned/tdnn_sp/decode_dev_clean_tgsmall
steps/nnet3/decode.sh: feature type is raw
steps/nnet3/decode.sh: feature type is raw
steps/nnet3/decode.sh: feature type is raw
steps/nnet3/decode.sh: feature type is raw
local/nnet3/run_tdnn.sh: there was a problem while decoding
