# This file was created by the command:
# steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3_cleaned/tdnn_sp_1c_1e_cmvn/configs/network.xconfig --config-dir exp/nnet3_cleaned/tdnn_sp_1c_1e_cmvn/configs
#It contains the same content as ./xconfig but it was parsed and
#default config values were set.
# See also ./xconfig.expanded.2

input name=ivector dim=100
input name=input dim=40
fixed-affine-layer name=lda affine-transform-file=exp/nnet3_cleaned/tdnn_sp_1c_1e_cmvn/configs/lda.mat delay=0 dim=300 input=Append(-2,-1,0,1,2,ReplaceIndex(ivector, t, 0)) write-init-config=True
relu-batchnorm-dropout-layer name=tdnn1 add-log-stddev=False bias-stddev= bottleneck-dim=-1 dim=1536 dropout-per-dim=False dropout-per-dim-continuous=False dropout-proportion=0.5 input=[-1] l2-regularize= learning-rate-factor= max-change=0.75 ng-affine-options= ng-linear-options= self-repair-scale=1e-05 target-rms=1.0
tdnnf-layer name=tdnnf2 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=1
tdnnf-layer name=tdnnf3 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=1
tdnnf-layer name=tdnnf4 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=1
tdnnf-layer name=tdnnf5 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=0
tdnnf-layer name=tdnnf6 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf7 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf8 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf9 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf10 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf11 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf12 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf13 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf14 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf15 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf16 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
tdnnf-layer name=tdnnf17 bottleneck-dim=160 bypass-scale=0.66 context=default dim=1536 dropout-proportion=-1.0 input=[-1] l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 time-stride=3
linear-component name=prefinal-l dim=256 input=[-1] l2-regularize= learning-rate-factor= max-change=0.75 orthonormal-constraint= param-stddev=
prefinal-layer name=prefinal big-dim=1536 input=prefinal-l l2-regularize=0.0 max-change=0.75 self-repair-scale=1e-05 small-dim=256
output-layer name=output bias-stddev=0.0 bottleneck-dim=-1 dim=5688 include-log-softmax=True input=prefinal l2-regularize= learning-rate-factor= max-change=1.5 ng-affine-options= ng-linear-options= objective-type=linear orthonormal-constraint=1.0 output-delay=0 param-stddev=0.0
